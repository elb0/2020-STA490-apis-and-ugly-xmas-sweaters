---
title: "STA490 special joint class"
output:
  html_document:
    df_print: paged
  html_notebook: default
---

Hi everyone! Welcome to this penultimate class of the Fall semester. Next week is the second set of project presentations and then it is winter holidays. The goal of today is to 1) have some fun, 2) further build some of your practical skills wrangling and visualising data and 3) gain experience using an API.

See the slides on the course overview page for more information.

# Getting set up

```{r libraries, message = FALSE, }
# Credit to danielle smith for this basis of this great little function: 
# https://gist.github.com/smithdanielle/9913897
install_check <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
}

# Here is a list of the packages we will need today
packages = c("tidyverse", "polite",
             "TMDb", "keyring", "glue", "lubridate", "ggpubr")

install_check(packages)

# Load tidyverse now, we'll load the others as we need them
library(tidyverse) # Liza's fave package of packages ever
library(glue) # awesome package that we don't have time to talk about
library(lubridate) # helps make dates much easier

```

# IMDB

```{r polite}
library(polite) # let's us check the robotstxt, and also pass user agent information to the site, if we choose

bow("https://www.imdb.com/search/keyword/?keywords=christmas&ref_=kw_nxt&sort=moviemeter,asc&mode=detail&page=2&title_type=movie")
  
```

Let's looks at the robots.txt and Terms and Conditions ourselves. 

```{r checksites, eval=FALSE}
browseURL("https://www.imdb.com/conditions")
browseURL("https://www.imdb.com/robots.txt")
```

So, can we ethically scrape IMDB?


# The Movie Database (TMDb)

Let's take a look a different online movie database...

```{r}
browseURL("https://www.themoviedb.org/terms-of-use")
```


**back to the slides!**

\newpage 

## API

We can't scrape ethically, but we can use the API. In fact, there exists a package to helps us do this easily in R! 

### Libraries we need
You need the `TMDb` package that helps us access the API through R. We're also going to install `keyring` which is a nice way to keep your private API key safe but still share all the code we're using.
`

```{r, setup, message=FALSE}
library(TMDb) # provides access to the API
library(keyring) # for storing our API key
```

### Set up API key, super secretly

```{r, eval=FALSE}
#This will create a pop-up prompting you for a password. Put your api key in there.
key_set("TMDB_API")
```

# The data
## Let's explore some functions!

You can find more information in the [documentation on CRAN](https://cran.r-project.org/web/packages/TMDb/TMDb.pdf) or on this more [interactive site](https://rdrr.io/cran/TMDb/)

Let's find out what kind of genre classifications we have.

```{r}
genres <- genres_movie_list(key_get("TMDB_API"))$genres
genres
```

We can use these ids later to help us search things.

##  A little error fixing for keywords

There is an error in the package for this function taht is suppowed to search keywrods, so I've edited it here.
```{r search_keyword}
search_keyword <- function(api_key, query, page=1){
    
    if(page<1 || page>1000){
        stop("page must be a number between 1 and 1000")
    }
    
    l <- list(page=page)
    l <- l[!is.na(l)]
    
    params <- paste("&", names(l), "=",l, sep="", collapse="")
    url <- fromJSON(GET(URLencode(url<-paste("http://api.themoviedb.org/3/search/keyword?api_key=", 
                                             api_key, "&query=", query, params, sep="")))$url)
    
    return(url)
    
}
```

**Opportunity: Put in a pull request on the GitHub for the package to fix this function!**
https://github.com/AndreaCapozio/TMDb 
 
```{r }
# now I want to find all the Christmas keywords I could be searching
search_keyword(key_get("TMDB_API"), query = "christmas")
```

Notice that this only has 20 rows... are there more Christmas keywords than just that? 20 seems like a suspicisoulsy tidy number...

Our problem is that this function can just pull one 'page' at a time, a page has 20 entries. Reading the documentation shows us that there are a maximum of 1000 pages but I think it is acutally 500 based on some testing.

Thankfully, we can find out how many pages there are by just looking at the `total_pages` list element. Convenient!

Now, we *could* do a `for` loop to get all the pages....but it seems like the more people program the less they like `for` loops. We can use the map functions from purrr to do what we want and keep our code very tidy. More info here: https://speakerdeck.com/jennybc/purrr-workshop.
            
```{r, getxmasids}
# write a function that runs this for command for any given page
one_page <- function(x) search_keyword(key_get("TMDB_API"), query = "christmas", page = x)

# make a vector of the pages, from 1 to the max page for this search
pages <- 1:one_page(1)$total_pages

# now use map_dfr (map specifcally for returning data frames) instead of a for loop
christmas_keywords <- map_dfr(pages, function(x) one_page(x)$results)
christmas_keywords

# later, for searching multiple IDs I need to make them a string seperated by | for "OR" or , for "AND"
xmas_ids <- glue_collapse(christmas_keywords$id, sep="|")
xmas_ids
```


### ACTVITY: Your turn! Find a keyword or set of key words you'd be interested in searching

```{r, getyourkeywords, eval=FALSE}
# write a function that runs this for command for any given page
one_page <- function(x) search_keyword(key_get("TMDB_API"), query = "<PUT SEARCH TERM HERE", page = x)

# make a vector of the pages, from 1 to the max page for this search
pages <- 1:one_page(1)$total_pages

# now use map_dfr (map specifcally for returning data frames) instead of a for loop
my_keywords <- map_dfr(pages, function(x) one_page(x)$results)
my_keywords

# later, for searching multiple IDs I need to make them a string seperated by | for "OR" or , for "AND"
keywords_ids <- glue_collapse(christmas_keywords$id, sep="|")
keywords_ids

# change eval=FALSE in the chunk options, so that is TRUE

```

## Searching for movies

`discover_movie()` lets us do some searching based on a range of critera. I want movies that are Romance genre, and have "christmas" related keywords.

```{r xmas_romance}
# Reusing the code structure above. This could probably be streamlined even better with a more general function
one_page <- function(x) discover_movie(key_get("TMDB_API"), with_genres = 10749, with_keywords = xmas_ids, page = x)
pages <- 1:one_page(1)$total_pages
christmas_romance <- map_dfr(pages, function(x) one_page(x)$results) %>% 
  mutate(genre_ids = as.character(genre_ids))
  
# write_csv(christmas_romance, "christmas_romance.csv")
```

### ACTIVITY: Set up a search of your own

```{r}

```

## Visualization time! But make it UGLY...

Great resources for colours in R: http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf 

```{r}

```

Background images in repo from:https://kosamari.github.io/sweaterify/ and  https://depositphotos.com/110626704/stock-illustration-christmas-sweater-pattern.html

# Your turn! Ugly graph challenge

Use this API (or the data I have provided) and make an extremely ugly and hard to read graph! The sky is the limit (warning: stop if you make your own eyes bleed.)

Email us your ugly creations and if we get enough we can make a class gallery.

# What else could we look at?

### Top voted movies?

```{r top10}
top10 <- edit %>% 
  arrange(desc(vote_count)) %>% 
  head(n = 10) %>% 
  select(title, poster_path)
top10

```

```{r, load posters, out.width="50%"}
url <- paste0("https://image.tmdb.org/t/p/w1280/", top10$poster_path)

knitr::include_graphics(url)
```



# Appendix

```{r}
# Here is an example of pulling a list (I got the id from the URL)
list_get(key_get("TMDB_API"), 7411)
```

This example uses a more serious keyword.

```{r, racism}
search_keyword(key_get("TMDB_API"), query = "racism")

one_page <- function(x) discover_movie(key_get("TMDB_API"), with_keywords = 12425, page = x)
pages <- 1:one_page(1)$total_pages
racism <- map_dfr(pages, function(x) one_page(x)$results)

glimpse(racism)

```
